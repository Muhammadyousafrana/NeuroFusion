{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammadyousafrana/NeuroFusion/blob/main/EGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torcheeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0UofOjZc9cE",
        "outputId": "b0f16461-ab3c-4dc5-a617-eacc2e371317"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torcheeg\n",
            "  Downloading torcheeg-1.1.3.tar.gz (251 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/251.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.4/251.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (2.2.2)\n",
            "Requirement already satisfied: xlrd>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (2.0.1)\n",
            "Collecting scipy<=1.10.1,>=1.7.3 (from torcheeg)\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.6.1)\n",
            "Collecting lmdb>=1.3.0 (from torcheeg)\n",
            "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: einops>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (0.8.1)\n",
            "Collecting mne>=1.0.3 (from torcheeg)\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting xmltodict>=0.13.0 (from torcheeg)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: networkx>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (3.4.2)\n",
            "Collecting PyWavelets>=1.3.0 (from torcheeg)\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting spectrum>=0.8.1 (from torcheeg)\n",
            "  Downloading spectrum-0.9.0.tar.gz (231 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.5/231.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchmetrics>=0.10.0 (from torcheeg)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting mne_connectivity>=0.4.0 (from torcheeg)\n",
            "  Downloading mne_connectivity-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pytorch-lightning>=1.9.5 (from torcheeg)\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting wfdb>=4.1.2 (from torcheeg)\n",
            "  Downloading wfdb-4.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (3.1.5)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (1.8.2)\n",
            "Collecting netCDF4>=1.6.5 (from mne_connectivity>=0.4.0->torcheeg)\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: xarray>=2023.11.0 in /usr/local/lib/python3.11/dist-packages (from mne_connectivity>=0.4.0->torcheeg) (2025.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->torcheeg) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->torcheeg) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->torcheeg) (2025.1)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.9.5->torcheeg) (2.5.1+cu124)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.9.5->torcheeg) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.9.5->torcheeg) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.9.5->torcheeg) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=1.9.5->torcheeg)\n",
            "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->torcheeg) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->torcheeg) (3.5.0)\n",
            "Collecting easydev (from spectrum>=0.8.1->torcheeg)\n",
            "  Downloading easydev-0.13.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pandas>=1.3.5 (from torcheeg)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from wfdb>=4.1.2->torcheeg) (2.32.3)\n",
            "INFO: pip is looking at multiple versions of wfdb to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting wfdb>=4.1.2 (from torcheeg)\n",
            "  Downloading wfdb-4.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb>=4.1.2->torcheeg) (0.13.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.9.5->torcheeg) (3.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.9.5->torcheeg) (75.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.0.3->torcheeg) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.0.3->torcheeg) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.0.3->torcheeg) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.0.3->torcheeg) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.0.3->torcheeg) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.0.3->torcheeg) (3.2.1)\n",
            "Collecting cftime (from netCDF4>=1.6.5->mne_connectivity>=0.4.0->torcheeg)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4>=1.6.5->mne_connectivity>=0.4.0->torcheeg) (2025.1.31)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne>=1.0.3->torcheeg) (4.3.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->torcheeg) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb>=4.1.2->torcheeg) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb>=4.1.2->torcheeg) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb>=4.1.2->torcheeg) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from SoundFile>=0.10.0->wfdb>=4.1.2->torcheeg) (1.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg) (3.17.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning>=1.9.5->torcheeg) (1.3.0)\n",
            "Collecting colorama<0.5.0,>=0.4.6 (from easydev->spectrum>=0.8.1->torcheeg)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting colorlog<7.0.0,>=6.8.2 (from easydev->spectrum>=0.8.1->torcheeg)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting line-profiler<5.0.0,>=4.1.2 (from easydev->spectrum>=0.8.1->torcheeg)\n",
            "  Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: pexpect<5.0.0,>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from easydev->spectrum>=0.8.1->torcheeg) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne>=1.0.3->torcheeg) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.9.5->torcheeg) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.9.5->torcheeg) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.9.5->torcheeg) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.9.5->torcheeg) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.9.5->torcheeg) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.9.5->torcheeg) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.9.5->torcheeg) (1.18.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb>=4.1.2->torcheeg) (2.22)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect<5.0.0,>=4.9.0->easydev->spectrum>=0.8.1->torcheeg) (0.7.0)\n",
            "Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mne_connectivity-0.7.0-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
            "Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading easydev-0.13.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (750 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.2/750.2 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torcheeg, spectrum\n",
            "  Building wheel for torcheeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torcheeg: filename=torcheeg-1.1.3-py3-none-any.whl size=466286 sha256=908baaee699a2e27afa6c5b4c78b268651c5e241373499178d0609adfd27c7ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/7e/e1/7004a323c223a4fce1b1c4b2c2afd8f608b4b5591a39008416\n",
            "  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectrum: filename=spectrum-0.9.0-cp311-cp311-linux_x86_64.whl size=236749 sha256=3d2b9f21211bfb74b2c3b059bdb7f4b0d2f43a9e12fdcfcd825dd55135bf3503\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/9c/de/eb558fbd03ea1540d3c908f23681f57f9d9e8c2a5cd08d6f42\n",
            "Successfully built torcheeg spectrum\n",
            "Installing collected packages: lmdb, xmltodict, scipy, PyWavelets, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, line-profiler, lightning-utilities, colorlog, colorama, cftime, nvidia-cusparse-cu12, nvidia-cudnn-cu12, netCDF4, easydev, wfdb, spectrum, nvidia-cusolver-cu12, mne, mne_connectivity, torchmetrics, pytorch-lightning, torcheeg\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.1 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyWavelets-1.8.0 cftime-1.6.4.post1 colorama-0.4.6 colorlog-6.9.0 easydev-0.13.3 lightning-utilities-0.12.0 line-profiler-4.2.0 lmdb-1.6.2 mne-1.9.0 mne_connectivity-0.7.0 netCDF4-1.7.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.0.post0 scipy-1.10.1 spectrum-0.9.0 torcheeg-1.1.3 torchmetrics-1.6.1 wfdb-4.1.2 xmltodict-0.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2BBjJhDrRe_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef7273cf-6db2-47ab-ef35-9a76a1f28bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-02-18 08:26:21] INFO (torcheeg/MainThread) 🔍 | Processing EEG data. Processed EEG data has been cached to \u001b[92m.torcheeg/datasets_1739867181995_9UGvG\u001b[0m.\n",
            "INFO:torcheeg:🔍 | Processing EEG data. Processed EEG data has been cached to \u001b[92m.torcheeg/datasets_1739867181995_9UGvG\u001b[0m.\n",
            "[2025-02-18 08:26:22] INFO (torcheeg/MainThread) ⏳ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n",
            "INFO:torcheeg:⏳ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n",
            "[PROCESS]:   0%|          | 0/23 [00:00<?, ?it/s]\n",
            "[RECORD 0]: 0it [00:00, ?it/s]\u001b[A\n",
            "[RECORD 0]: 1it [00:08,  8.52s/it]\u001b[A\n",
            "[RECORD 0]: 21it [00:08,  3.41it/s]\u001b[A\n",
            "[RECORD 0]: 41it [00:08,  7.93it/s]\u001b[A\n",
            "[RECORD 0]: 60it [00:08, 13.71it/s]\u001b[A\n",
            "[RECORD 0]: 79it [00:08, 21.35it/s]\u001b[A\n",
            "[RECORD 0]: 99it [00:09, 31.70it/s]\u001b[A\n",
            "[RECORD 0]: 119it [00:09, 44.47it/s]\u001b[A\n",
            "[RECORD 0]: 138it [00:09, 58.70it/s]\u001b[A\n",
            "[RECORD 0]: 157it [00:09, 74.63it/s]\u001b[A\n",
            "[RECORD 0]: 176it [00:09, 91.20it/s]\u001b[A\n",
            "[RECORD 0]: 195it [00:09, 107.65it/s]\u001b[A\n",
            "[RECORD 0]: 214it [00:09, 122.51it/s]\u001b[A\n",
            "[RECORD 0]: 233it [00:09, 134.95it/s]\u001b[A\n",
            "[RECORD 0]: 252it [00:09, 143.10it/s]\u001b[A\n",
            "[RECORD 0]: 271it [00:09, 154.42it/s]\u001b[A\n",
            "[RECORD 0]: 289it [00:10, 160.47it/s]\u001b[A\n",
            "[RECORD 0]: 307it [00:10, 165.69it/s]\u001b[A\n",
            "[RECORD 0]: 325it [00:10, 167.94it/s]\u001b[A\n",
            "[RECORD 0]: 343it [00:10, 170.93it/s]\u001b[A\n",
            "[RECORD 0]: 362it [00:10, 176.37it/s]\u001b[A\n",
            "[RECORD 0]: 381it [00:10, 177.84it/s]\u001b[A\n",
            "[RECORD 0]: 400it [00:10, 179.47it/s]\u001b[A\n",
            "[RECORD 0]: 419it [00:10, 180.88it/s]\u001b[A\n",
            "[RECORD 0]: 438it [00:10, 180.68it/s]\u001b[A\n",
            "[RECORD 0]: 457it [00:11, 182.13it/s]\u001b[A\n",
            "[RECORD 0]: 476it [00:11, 183.64it/s]\u001b[A\n",
            "[RECORD 0]: 496it [00:11, 186.53it/s]\u001b[A\n",
            "[RECORD 0]: 515it [00:11, 186.27it/s]\u001b[A\n",
            "[RECORD 0]: 535it [00:11, 188.48it/s]\u001b[A\n",
            "[RECORD 0]: 554it [00:11, 187.59it/s]\u001b[A\n",
            "[RECORD 0]: 574it [00:11, 189.56it/s]\u001b[A\n",
            "[RECORD 0]: 593it [00:11, 185.66it/s]\u001b[A\n",
            "[RECORD 0]: 612it [00:11, 184.61it/s]\u001b[A\n",
            "[RECORD 0]: 631it [00:11, 184.87it/s]\u001b[A\n",
            "[RECORD 0]: 650it [00:12, 183.80it/s]\u001b[A\n",
            "[RECORD 0]: 669it [00:12, 184.07it/s]\u001b[A\n",
            "[RECORD 0]: 688it [00:12, 184.01it/s]\u001b[A\n",
            "[RECORD 0]: 708it [00:12, 187.80it/s]\u001b[A\n",
            "[RECORD 0]: 727it [00:12, 185.41it/s]\u001b[A\n",
            "[RECORD 0]: 746it [00:12, 184.62it/s]\u001b[A\n",
            "[RECORD 0]: 765it [00:12, 182.42it/s]\u001b[A\n",
            "[RECORD 0]: 784it [00:12, 178.76it/s]\u001b[A\n",
            "[RECORD 0]: 802it [00:12, 178.46it/s]\u001b[A\n",
            "[RECORD 0]: 820it [00:12, 177.61it/s]\u001b[A\n",
            "[RECORD 0]: 839it [00:13, 179.53it/s]\u001b[A\n",
            "[RECORD 0]: 858it [00:13, 180.50it/s]\u001b[A\n",
            "[RECORD 0]: 878it [00:13, 185.94it/s]\u001b[A\n",
            "[RECORD 0]: 897it [00:13, 186.59it/s]\u001b[A\n",
            "[RECORD 0]: 916it [00:13, 185.24it/s]\u001b[A\n",
            "[RECORD 0]: 935it [00:13, 184.91it/s]\u001b[A\n",
            "[RECORD 0]: 954it [00:13, 180.83it/s]\u001b[A\n",
            "[RECORD 0]: 973it [00:13, 177.88it/s]\u001b[A\n",
            "[RECORD 0]: 992it [00:13, 180.34it/s]\u001b[A\n",
            "[RECORD 0]: 1011it [00:14, 182.85it/s]\u001b[A\n",
            "[RECORD 0]: 1030it [00:14, 183.30it/s]\u001b[A\n",
            "[RECORD 0]: 1049it [00:14, 183.33it/s]\u001b[A\n",
            "[RECORD 0]: 1069it [00:14, 186.04it/s]\u001b[A\n",
            "[RECORD 0]: 1088it [00:14, 184.60it/s]\u001b[A\n",
            "[RECORD 0]: 1109it [00:14, 189.93it/s]\u001b[A\n",
            "[RECORD 0]: 1129it [00:14, 190.49it/s]\u001b[A\n",
            "[RECORD 0]: 1149it [00:14, 189.47it/s]\u001b[A\n",
            "[RECORD 0]: 1169it [00:14, 189.98it/s]\u001b[A\n",
            "[RECORD 0]: 1189it [00:14, 189.82it/s]\u001b[A\n",
            "[RECORD 0]: 1210it [00:15, 193.11it/s]\u001b[A\n",
            "[RECORD 0]: 1231it [00:15, 196.60it/s]\u001b[A\n",
            "[RECORD 0]: 1251it [00:15, 196.51it/s]\u001b[A\n",
            "[RECORD 0]: 1271it [00:15, 196.25it/s]\u001b[A\n",
            "[RECORD 0]: 1291it [00:15, 195.73it/s]\u001b[A\n",
            "[RECORD 0]: 1311it [00:15, 192.52it/s]\u001b[A\n",
            "[RECORD 0]: 1331it [00:15, 191.49it/s]\u001b[A\n",
            "[RECORD 0]: 1351it [00:15, 186.54it/s]\u001b[A\n",
            "[RECORD 0]: 1370it [00:15, 182.25it/s]\u001b[A\n",
            "[RECORD 0]: 1389it [00:16, 183.72it/s]\u001b[A\n",
            "[RECORD 0]: 1408it [00:16, 184.26it/s]\u001b[A\n",
            "[RECORD 0]: 1427it [00:16, 184.51it/s]\u001b[A\n",
            "[RECORD 0]: 1447it [00:16, 186.54it/s]\u001b[A\n",
            "[RECORD 0]: 1467it [00:16, 188.03it/s]\u001b[A\n",
            "[RECORD 0]: 1486it [00:16, 187.10it/s]\u001b[A\n",
            "[RECORD 0]: 1505it [00:16, 186.45it/s]\u001b[A\n",
            "[RECORD 0]: 1524it [00:16, 185.22it/s]\u001b[A\n",
            "[RECORD 0]: 1543it [00:16, 182.87it/s]\u001b[A\n",
            "[RECORD 0]: 1562it [00:16, 183.37it/s]\u001b[A\n",
            "[RECORD 0]: 1581it [00:17, 183.69it/s]\u001b[A\n",
            "[RECORD 0]: 1601it [00:17, 186.69it/s]\u001b[A\n",
            "[RECORD 0]: 1620it [00:17, 186.28it/s]\u001b[A\n",
            "[RECORD 0]: 1639it [00:17, 187.12it/s]\u001b[A\n",
            "[RECORD 0]: 1658it [00:17, 187.57it/s]\u001b[A\n",
            "[RECORD 0]: 1678it [00:17, 188.73it/s]\u001b[A\n",
            "[RECORD 0]: 1697it [00:17, 187.38it/s]\u001b[A\n",
            "[RECORD 0]: 1716it [00:17, 187.49it/s]\u001b[A\n",
            "[RECORD 0]: 1735it [00:17, 184.87it/s]\u001b[A\n",
            "[RECORD 0]: 1754it [00:17, 185.10it/s]\u001b[A\n",
            "[RECORD 0]: 1773it [00:18, 184.37it/s]\u001b[A\n",
            "[RECORD 0]: 1792it [00:18, 184.56it/s]\u001b[A\n",
            "[RECORD 0]: 1811it [00:18, 185.17it/s]\u001b[A\n",
            "[RECORD 0]: 1831it [00:18, 187.51it/s]\u001b[A\n",
            "[RECORD 0]: 1850it [00:18, 187.42it/s]\u001b[A\n",
            "[RECORD 0]: 1869it [00:18, 185.99it/s]\u001b[A\n",
            "[RECORD 0]: 1888it [00:18, 186.03it/s]\u001b[A\n",
            "[RECORD 0]: 1907it [00:18, 178.99it/s]\u001b[A\n",
            "[RECORD 0]: 1925it [00:18, 178.55it/s]\u001b[A\n",
            "[RECORD 0]: 1945it [00:19, 181.97it/s]\u001b[A\n",
            "[RECORD 0]: 1964it [00:19, 183.55it/s]\u001b[A\n",
            "[RECORD 0]: 1983it [00:19, 185.08it/s]\u001b[A\n",
            "[RECORD 0]: 2002it [00:19, 183.59it/s]\u001b[A\n",
            "[RECORD 0]: 2021it [00:19, 184.18it/s]\u001b[A\n",
            "[RECORD 0]: 2040it [00:19, 185.18it/s]\u001b[A\n",
            "[RECORD 0]: 2059it [00:19, 184.09it/s]\u001b[A\n",
            "[RECORD 0]: 2078it [00:19, 183.11it/s]\u001b[A\n",
            "[RECORD 0]: 2097it [00:19, 183.29it/s]\u001b[A\n",
            "[RECORD 0]: 2116it [00:19, 184.35it/s]\u001b[A\n",
            "[RECORD 0]: 2136it [00:20, 186.64it/s]\u001b[A\n",
            "[RECORD 0]: 2156it [00:20, 188.83it/s]\u001b[A\n",
            "[RECORD 0]: 2177it [00:20, 194.90it/s]\u001b[A\n",
            "[RECORD 0]: 2198it [00:20, 196.96it/s]\u001b[A\n",
            "[RECORD 0]: 2218it [00:20, 197.41it/s]\u001b[A\n",
            "[RECORD 0]: 2238it [00:20, 196.92it/s]\u001b[A\n",
            "[RECORD 0]: 2258it [00:20, 195.50it/s]\u001b[A\n",
            "[RECORD 0]: 2278it [00:20, 195.60it/s]\u001b[A\n",
            "[RECORD 0]: 2298it [00:20, 192.91it/s]\u001b[A\n",
            "[RECORD 0]: 2318it [00:20, 192.34it/s]\u001b[A\n",
            "[RECORD 0]: 2338it [00:21, 193.03it/s]\u001b[A\n",
            "[RECORD 0]: 2358it [00:21, 192.43it/s]\u001b[A\n",
            "[RECORD 0]: 2378it [00:21, 189.96it/s]\u001b[A\n",
            "[RECORD 0]: 2398it [00:21, 180.63it/s]\u001b[A\n",
            "[RECORD 0]: 2417it [00:21, 183.20it/s]\u001b[A\n",
            "[RECORD 0]: 2436it [00:21, 182.44it/s]\u001b[A\n",
            "[RECORD 0]: 2456it [00:21, 184.88it/s]\u001b[A\n",
            "[RECORD 0]: 2476it [00:21, 186.68it/s]\u001b[A\n",
            "[RECORD 0]: 2495it [00:21, 187.57it/s]\u001b[A\n",
            "[RECORD 0]: 2514it [00:22, 188.01it/s]\u001b[A\n",
            "[RECORD 0]: 2535it [00:22, 191.82it/s]\u001b[A\n",
            "[RECORD 0]: 2555it [00:22, 189.47it/s]\u001b[A\n",
            "[RECORD 0]: 2575it [00:22, 189.34it/s]\u001b[A\n",
            "[RECORD 0]: 2595it [00:22, 191.65it/s]\u001b[A\n",
            "[RECORD 0]: 2616it [00:22, 196.08it/s]\u001b[A\n",
            "[RECORD 0]: 2636it [00:22, 191.28it/s]\u001b[A\n",
            "[RECORD 0]: 2656it [00:22, 188.04it/s]\u001b[A\n",
            "[RECORD 0]: 2675it [00:22, 185.04it/s]\u001b[A\n",
            "[RECORD 0]: 2695it [00:22, 186.79it/s]\u001b[A\n",
            "[RECORD 0]: 2714it [00:23, 186.01it/s]\u001b[A\n",
            "[RECORD 0]: 2734it [00:23, 189.25it/s]\u001b[A\n",
            "[RECORD 0]: 2754it [00:23, 191.10it/s]\u001b[A\n",
            "[RECORD 0]: 2774it [00:23, 191.29it/s]\u001b[A\n",
            "[RECORD 0]: 2794it [00:23, 192.32it/s]\u001b[A\n",
            "[RECORD 0]: 2815it [00:23, 195.60it/s]\u001b[A\n",
            "[RECORD 0]: 2835it [00:23, 195.75it/s]\u001b[A\n",
            "[RECORD 0]: 2855it [00:23, 190.70it/s]\u001b[A\n",
            "[RECORD 0]: 2875it [00:23, 187.55it/s]\u001b[A\n",
            "[RECORD 0]: 2895it [00:24, 190.78it/s]\u001b[A\n",
            "[RECORD 0]: 2916it [00:24, 194.60it/s]\u001b[A\n",
            "[RECORD 0]: 2936it [00:24, 194.92it/s]\u001b[A\n",
            "[RECORD 0]: 2956it [00:24, 192.94it/s]\u001b[A\n",
            "[RECORD 0]: 2976it [00:24, 191.49it/s]\u001b[A\n",
            "[RECORD 0]: 2996it [00:24, 191.57it/s]\u001b[A\n",
            "[RECORD 0]: 3017it [00:24, 194.86it/s]\u001b[A\n",
            "[RECORD 0]: 3037it [00:24, 192.35it/s]\u001b[A\n",
            "[RECORD 0]: 3057it [00:24, 192.19it/s]\u001b[A\n",
            "[RECORD 0]: 3077it [00:24, 191.94it/s]\u001b[A\n",
            "[RECORD 0]: 3097it [00:25, 188.96it/s]\u001b[A\n",
            "[RECORD 0]: 3117it [00:25, 191.32it/s]\u001b[A\n",
            "[RECORD 0]: 3137it [00:25, 190.65it/s]\u001b[A\n",
            "[RECORD 0]: 3157it [00:25, 190.17it/s]\u001b[A\n",
            "[RECORD 0]: 3177it [00:25, 190.16it/s]\u001b[A\n",
            "[RECORD 0]: 3197it [00:25, 190.35it/s]\u001b[A\n",
            "[RECORD 0]: 3217it [00:25, 190.88it/s]\u001b[A\n",
            "[RECORD 0]: 3237it [00:25, 188.06it/s]\u001b[A\n",
            "[RECORD 0]: 3256it [00:25, 185.39it/s]\u001b[A\n",
            "[RECORD 0]: 3275it [00:26, 186.45it/s]\u001b[A\n",
            "[RECORD 0]: 3294it [00:26, 185.38it/s]\u001b[A\n",
            "[RECORD 0]: 3313it [00:26, 185.37it/s]\u001b[A\n",
            "[RECORD 0]: 3333it [00:26, 186.99it/s]\u001b[A\n",
            "[RECORD 0]: 3352it [00:26, 187.75it/s]\u001b[A\n",
            "[RECORD 0]: 3371it [00:26, 183.95it/s]\u001b[A\n",
            "[RECORD 0]: 3391it [00:26, 186.29it/s]\u001b[A\n",
            "[RECORD 0]: 3410it [00:26, 168.95it/s]\u001b[A\n",
            "[RECORD 0]: 3428it [00:26, 169.82it/s]\u001b[A\n",
            "[RECORD 0]: 3447it [00:26, 174.04it/s]\u001b[A\n",
            "[RECORD 0]: 3466it [00:27, 176.65it/s]\u001b[A\n",
            "[RECORD 0]: 3485it [00:27, 178.79it/s]\u001b[A\n",
            "[RECORD 0]: 3504it [00:27, 180.39it/s]\u001b[A\n",
            "[RECORD 0]: 3523it [00:27, 182.75it/s]\u001b[A\n",
            "[RECORD 0]: 3543it [00:27, 187.09it/s]\u001b[A\n",
            "[RECORD 0]: 3563it [00:27, 189.57it/s]\u001b[A\n",
            "[RECORD 0]: 3583it [00:27, 191.80it/s]\u001b[A\n",
            "[RECORD 0]: 3603it [00:27, 186.70it/s]\u001b[A\n",
            "[RECORD 0]: 3622it [00:27, 182.65it/s]\u001b[A\n",
            "[RECORD 0]: 3642it [00:28, 187.43it/s]\u001b[A\n",
            "[RECORD 0]: 3662it [00:28, 189.08it/s]\u001b[A\n",
            "[RECORD 0]: 3681it [00:28, 187.67it/s]\u001b[A\n",
            "[RECORD 0]: 3700it [00:28, 186.94it/s]\u001b[A\n",
            "[RECORD 0]: 3720it [00:28, 188.36it/s]\u001b[A\n",
            "[RECORD 0]: 3739it [00:28, 186.70it/s]\u001b[A\n",
            "[PROCESS]: 100%|██████████| 23/23 [10:26<00:00, 27.22s/it]\n",
            "[2025-02-18 08:37:00] INFO (torcheeg/MainThread) ✅ | All processed EEG data has been cached to .torcheeg/datasets_1739867181995_9UGvG.\n",
            "INFO:torcheeg:✅ | All processed EEG data has been cached to .torcheeg/datasets_1739867181995_9UGvG.\n",
            "[2025-02-18 08:37:00] INFO (torcheeg/MainThread) 😊 | Please set \u001b[92mio_path\u001b[0m to \u001b[92m.torcheeg/datasets_1739867181995_9UGvG\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n",
            "INFO:torcheeg:😊 | Please set \u001b[92mio_path\u001b[0m to \u001b[92m.torcheeg/datasets_1739867181995_9UGvG\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[ 0.9362,  0.8663,  0.8809,  ...,  0.8372,  0.8780,  0.9275],\n",
            "         [-0.6853, -0.7348, -0.7494,  ..., -0.8134, -0.7814, -0.7552],\n",
            "         [-0.0216,  0.1676,  0.0395,  ..., -0.5747, -0.8426, -0.9910],\n",
            "         ...,\n",
            "         [ 1.3117,  1.3816,  1.3496,  ...,  1.0002,  0.8896,  0.8576],\n",
            "         [ 0.5839,  0.8489,  0.5956,  ...,  0.1676, -0.1177, -0.4233],\n",
            "         [-0.3302,  0.1356, -0.1118,  ..., -0.5019, -1.0784, -1.5150]]]), 0)\n"
          ]
        }
      ],
      "source": [
        "from torcheeg.datasets import DREAMERDataset\n",
        "from torcheeg import transforms\n",
        "from torcheeg.datasets.constants import DREAMER_CHANNEL_LOCATION_DICT\n",
        "\n",
        "dataset = DREAMERDataset(mat_path='/content/drive/MyDrive/DREAMER.mat',\n",
        "                         offline_transform=transforms.Compose([\n",
        "                             transforms.MeanStdNormalize(),\n",
        "                             transforms.To2d()\n",
        "                         ]),\n",
        "                         online_transform=transforms.Compose([\n",
        "                          transforms.ToTensor(),\n",
        "                        ]),\n",
        "                         label_transform=transforms.Compose([\n",
        "                             transforms.Select('valence'),\n",
        "                             transforms.Binary(5.0),\n",
        "                         ]))\n",
        "print(dataset[0])\n",
        "# EEG signal (torch.Tensor[4, 9, 9]),\n",
        "# coresponding baseline signal (torch.Tensor[4, 9, 9]),\n",
        "# label (int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torcheeg.io import EEGSignalIO\n",
        "import numpy as np\n",
        "eeg_io = EEGSignalIO('.torcheeg/datasets_1739867181995_9UGvG')\n",
        "key = eeg_io.write_eeg(np.random.randn(32, 128))\n",
        "eeg = eeg_io.read_eeg(key)\n",
        "eeg.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpt9Jq3AcT5u",
        "outputId": "ff8d4e69-5f8a-40b9-ce18-f7ed373df4c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_scatter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYvwTtD2tAse",
        "outputId": "6065e2e8-deb9-4b33-fee5-36a0b6ea5475"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_scatter\n",
            "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch_scatter\n",
            "  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=3618856 sha256=3a88d1504fc5f6ef94dc1723f63bf434c63faabeac2c719108a13216991f4044\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\n",
            "Successfully built torch_scatter\n",
            "Installing collected packages: torch_scatter\n",
            "Successfully installed torch_scatter-2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torcheeg.models import DGCNN\n",
        "from torcheeg.datasets import DREAMERDataset\n",
        "from torcheeg import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "# Define the DGCNN model\n",
        "model = DGCNN(in_channels=4,  # 4 frequency bands\n",
        "              num_electrodes=81,  # 9x9 grid = 81 electrodes after ToGrid()\n",
        "              hid_channels=32,\n",
        "              num_layers=2,\n",
        "              num_classes=2)  # Binary classification\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Get a batch of data\n",
        "x, y = next(iter(dataloader))\n",
        "\n",
        "# Reshape (4, 9, 9) into (64, 81, 4) since DGCNN's BatchNorm1d expects [batch_size, num_electrodes, in_channels]\n",
        "# The original reshape was incorrect and caused the mismatch in dimensions\n",
        "x = x.view(x.size(0), -1)\n",
        "x = x[:, :81*4].view(x.size(0), 81, 4)\n",
        "# Forward pass\n",
        "output = model(x)\n",
        "print(output.shape)  # Should be (batch_size, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltn505Y3pCum",
        "outputId": "e13f7cd3-5a88-486d-d885-d2b3cbf37014"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)  # L2 regularization added\n"
      ],
      "metadata": {
        "id": "a-9r8betC0H0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10  # Set your number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()  # Zero out the gradients\n",
        "\n",
        "        # Reshape the inputs for DGCNN\n",
        "        # The input should be (batch_size, num_electrodes, in_channels)\n",
        "        inputs = inputs.view(inputs.size(0), -1)\n",
        "        inputs = inputs[:, :81*4].view(inputs.size(0), 81, 4)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKbiyNxayvoO",
        "outputId": "b397406c-b711-4ecd-d0a3-f10a39408ec2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4493, Accuracy: 83.51%\n",
            "Epoch [2/10], Loss: 0.4415, Accuracy: 83.54%\n",
            "Epoch [3/10], Loss: 0.4388, Accuracy: 83.54%\n",
            "Epoch [4/10], Loss: 0.4373, Accuracy: 83.54%\n",
            "Epoch [5/10], Loss: 0.4361, Accuracy: 83.54%\n",
            "Epoch [6/10], Loss: 0.4352, Accuracy: 83.55%\n",
            "Epoch [7/10], Loss: 0.4338, Accuracy: 83.81%\n",
            "Epoch [8/10], Loss: 0.4329, Accuracy: 83.87%\n",
            "Epoch [9/10], Loss: 0.4319, Accuracy: 83.92%\n",
            "Epoch [10/10], Loss: 0.4300, Accuracy: 83.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10  # Set your number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()  # Zero out the gradients\n",
        "\n",
        "        # Reshape the inputs for DGCNN\n",
        "        # The input should be (batch_size, num_electrodes, in_channels)\n",
        "        # Assuming inputs.shape is (64, 1, 14, 128)\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten to (64, 1*14*128) = (64, 1792)\n",
        "        inputs = inputs[:, :81*4].view(inputs.size(0), 81, 4) # Select first 81*4 elements and reshape to (64, 81, 4)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGTgFTyjy05v",
        "outputId": "e74bea4a-3fba-4526-88e2-75a4d831dbd0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5328, Accuracy: 83.40%\n",
            "Epoch [2/10], Loss: 0.5223, Accuracy: 83.53%\n",
            "Epoch [3/10], Loss: 1.0523, Accuracy: 83.49%\n",
            "Epoch [4/10], Loss: 0.8126, Accuracy: 83.52%\n",
            "Epoch [5/10], Loss: 0.5259, Accuracy: 83.54%\n",
            "Epoch [6/10], Loss: 14.7197, Accuracy: 83.41%\n",
            "Epoch [7/10], Loss: 0.5270, Accuracy: 83.54%\n",
            "Epoch [8/10], Loss: 0.5249, Accuracy: 83.54%\n",
            "Epoch [9/10], Loss: 0.5232, Accuracy: 83.54%\n",
            "Epoch [10/10], Loss: 0.5240, Accuracy: 83.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming 'dataset' is a DataLoader or Dataset object, and each sample is a tuple of (signal, label)\n",
        "signals = []\n",
        "for x, _ in dataset:\n",
        "    # x is the signal part, append it to signals list\n",
        "    signals.append(x.numpy())  # Convert to numpy array if it's a torch tensor\n",
        "\n",
        "# Stack all signals to form a single numpy array\n",
        "signals = np.concatenate(signals, axis=0)\n",
        "\n",
        "# Flatten the signals to treat all elements as part of the same dataset\n",
        "flattened_signals = signals.flatten()\n",
        "\n",
        "# Calculate the total mean and standard deviation\n",
        "total_mean = np.mean(flattened_signals)\n",
        "total_std = np.std(flattened_signals)\n",
        "\n",
        "print(\"Total mean of all signals:\", total_mean)\n",
        "print(\"Total standard deviation of all signals:\", total_std)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b7lvFP99JhI",
        "outputId": "b68a2860-7e6d-41f0-aa6d-22a08caebaf4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total mean of all signals: 4.6674126e-11\n",
            "Total standard deviation of all signals: 0.9999991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torcheeg import transforms\n",
        "from torcheeg.models import ArjunViT\n",
        "import torchaudio\n",
        "\n",
        "# Define the original sample rate of the DREAMER dataset manually\n",
        "orig_freq = 256\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define the ArjunViT model\n",
        "model = ArjunViT(chunk_size=4,\n",
        "                 t_patch_size=1,\n",
        "                 num_electrodes=81,\n",
        "                 num_classes=2)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10  # Number of epochs to train\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()  # Zero out gradients\n",
        "\n",
        "        # Check the shape of your input tensor\n",
        "        # print(\"Input tensor shape:\", x.shape)\n",
        "\n",
        "        # Reshape to (batch_size, num_electrodes, chunk_size) for ArjunViT\n",
        "        # Assuming x.shape is (64, 1, 14, 128)\n",
        "        x = x.view(x.size(0), -1)  # Flatten to (64, 1*14*128) = (64, 1792)\n",
        "        x = x[:, :81*4].view(x.size(0), 81, 4) # Select first 81*4 elements and reshape to (64, 81, 4)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(x)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(outputs, y)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (predicted == y).sum().item()\n",
        "\n",
        "    # Calculate average loss and accuracy for the epoch\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQAcpDRo3Y81",
        "outputId": "033e3594-71e8-48ec-ee38-a23a038133ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4510, Accuracy: 83.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbOD1naKJtxV",
        "outputId": "01589758-a4ad-4e82-e906-4b3d3b8091e6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.25.6)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "dummy_input = torch.randn(64, 81,4)\n",
        "\n",
        "# Export the model to ONNX format\n",
        "onnx_path = \"arjun_vit_model.onnx\"\n",
        "torch.onnx.export(model,               # The trained model\n",
        "                  dummy_input,         # Dummy input for tracing\n",
        "                  onnx_path,           # Output file path\n",
        "                  input_names=['input'],   # Input name\n",
        "                  output_names=['output'], # Output name\n",
        "                  opset_version=12,         # ONNX opset version (ensure compatibility)\n",
        "                  do_constant_folding=True, # Optimize constant folding\n",
        "                  dynamic_axes={'input': {0: 'batch_size'},  # Dynamic batch size\n",
        "                                'output': {0: 'batch_size'}})\n",
        "\n",
        "print(f\"Model saved to {onnx_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSvdafky3ry5",
        "outputId": "4e914d91-05c1-4350-81bf-48b8f2b19324"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to arjun_vit_model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5sKS6MQgJVSf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1QYzbt_zX_pZO2LWkt_aumfYf9Maqb8Rn",
      "authorship_tag": "ABX9TyNmnanqVEZb3PRsMOWwwfv4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}